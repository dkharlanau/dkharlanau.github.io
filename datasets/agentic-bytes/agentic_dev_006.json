{
  "byte_id": "agentic_dev_006",
  "title": "Reranking: Choosing the Right Knowledge After Retrieval",
  "level": "foundation",
  "domain": [
    "agentic-development",
    "rag",
    "retrieval-quality"
  ],
  "intent": "Understand why initial retrieval is not enough and how reranking helps an agent select the most relevant and safe knowledge.",
  "core_idea": {
    "one_liner": "Retrieval finds candidates; reranking chooses the answer.",
    "why_it_matters": [
      "Vector search returns similar text, not necessarily the right rule.",
      "Multiple chunks may match — agents must pick the best one.",
      "Reranking reduces confident-but-wrong answers."
    ]
  },
  "definition": {
    "reranking": "A second-pass evaluation where retrieved chunks are scored again against the actual question and intent."
  },
  "why_retrieval_alone_fails": [
    "Semantic similarity ≠ applicability",
    "Generic chunks often outrank specific ones",
    "Examples may outrank rules",
    "Outdated chunks may still look similar"
  ],
  "common_reranking_signals": [
    {
      "signal": "Question intent match",
      "description": "Does the chunk answer a 'how', 'when', 'why', or 'what' question?"
    },
    {
      "signal": "Chunk type",
      "description": "Decision/checklist chunks often outrank narrative explanations."
    },
    {
      "signal": "Metadata fit",
      "description": "Domain, system, version, and validity alignment."
    },
    {
      "signal": "Specificity",
      "description": "Concrete rules and steps outrank generic advice."
    }
  ],
  "reranking_strategies": [
    {
      "name": "LLM-based reranking",
      "description": "Ask the model to score each chunk for relevance to the exact question.",
      "pros": [
        "High accuracy",
        "Understands intent"
      ],
      "cons": [
        "Extra latency",
        "Extra cost"
      ]
    },
    {
      "name": "Rule-based reranking",
      "description": "Boost or penalize chunks using metadata rules.",
      "pros": [
        "Fast",
        "Deterministic"
      ],
      "cons": [
        "Needs good metadata",
        "Less flexible"
      ]
    },
    {
      "name": "Hybrid reranking",
      "description": "Rules first, LLM second.",
      "pros": [
        "Balanced cost and quality"
      ],
      "cons": [
        "More complex to implement"
      ]
    }
  ],
  "micro_example": {
    "scenario": "Question: 'When should MDG replication be asynchronous?'",
    "retrieved_chunks": [
      "General replication overview",
      "Async vs sync decision rule",
      "Replication error troubleshooting"
    ],
    "reranked_result": [
      "Async vs sync decision rule",
      "General replication overview"
    ],
    "reason": "Decision rule matches intent ('when should') and chunk type."
  },
  "failure_modes": [
    "No reranking → first chunk wins by accident",
    "Reranking ignores metadata",
    "Overweighting examples over rules",
    "High latency due to reranking everything"
  ],
  "guards": [
    "Always rerank for decision-critical questions.",
    "Limit reranking to top-N retrieved chunks.",
    "Log which chunk was chosen and why."
  ],
  "teach_it_in_english": {
    "simple_explanation": "Search brings options; reranking makes the choice.",
    "one_sentence_definition": "Reranking is how an agent decides which knowledge actually applies."
  },
  "practical_checklist": [
    "Does the chosen chunk match the question intent?",
    "Is it the right type (rule vs explanation)?",
    "Is metadata aligned with the context?",
    "Can the agent explain why this chunk was selected?"
  ],
  "tags": [
    "reranking",
    "rag",
    "retrieval",
    "answer-selection"
  ],
  "meta": {
    "schema": "dkharlanau.dataset.byte",
    "schema_version": "1.1",
    "dataset": "agentic-bytes",
    "source_project": "cv-ai",
    "source_path": "agentic-bytes/agentic_dev_006.json",
    "generated_at_utc": "2026-02-03T14:33:32+00:00",
    "creator": {
      "name": "Dzmitryi Kharlanau",
      "role": "SAP Lead",
      "website": "https://dkharlanau.github.io",
      "linkedin": "https://www.linkedin.com/in/dkharlanau"
    },
    "attribution": {
      "attribution_required": true,
      "preferred_citation": "Dzmitryi Kharlanau (SAP Lead). Dataset bytes: https://dkharlanau.github.io"
    },
    "license": {
      "name": "",
      "spdx": "",
      "url": ""
    },
    "links": {
      "website": "https://dkharlanau.github.io",
      "linkedin": "https://www.linkedin.com/in/dkharlanau"
    },
    "contact": {
      "preferred": "linkedin",
      "linkedin": "https://www.linkedin.com/in/dkharlanau"
    },
    "canonical_url": "https://dkharlanau.github.io/datasets/agentic-bytes/agentic_dev_006.json",
    "created_at_utc": "2026-02-03T14:33:32+00:00",
    "updated_at_utc": "2026-02-03T15:29:02+00:00",
    "provenance": {
      "source_type": "chat_export_extraction",
      "note": "Extracted and curated by Dzmitryi Kharlanau; enriched for attribution and crawler indexing."
    },
    "entity_type": "agentic_byte",
    "entity_subtype": "level:foundation",
    "summary": "Understand why initial retrieval is not enough and how reranking helps an agent select the most relevant and safe knowledge."
  }
}
